# CS465_ElmagbariR
Space Adventure Game

  The project I chose involves creating a virtual reality (VR) space game where players interact with a simulated moon base environment. The main idea is to learn how to design and develop interactive virtual experiences using Unity and VR technologies. This project is important because virtual reality is becoming increasingly common in gaming and education, providing immersive experiences that can enhance learning, entertainment, and human-computer interaction (HCI).

  Previous research has explored how VR environments enhance user experiences and interactions. For instance, Bowman and McMahan (2007) studied user interaction techniques in virtual environments, finding that realistic interactions significantly improved user engagement and immersion. Another relevant study by Jerald (2015) emphasized the importance of intuitive interactions in VR, highlighting how naturalistic interactions, such as using hand movements for grabbing or shooting, improve user satisfaction and reduce cognitive load. Additionally, a recent study by Wilson and Soranzo (2015) discussed the impact of visual realism in VR environments, concluding that detailed visuals substantially increased immersion and presence, making the virtual experience more compelling. NASA's research has also shown that VR and augmented reality (AR) are powerful tools for education and training, particularly in space exploration scenarios. NASA currently employs AR and VR aboard the International Space Station to teach astronauts about space procedures, demonstrating its effectiveness as an educational tool (NASA, 2020). VR technology allows users to experience complex concepts and environments firsthand, significantly enhancing learning experiences (VR.Space, 2022). Furthermore, NASA's VR programs have successfully introduced scientific concepts and inspired interest in space exploration among users (NASA Spinoff, 2019).
  
  In this project, I will create a VR space game using Unity and Meta Quest 3. Unlike the reviewed literature, which mainly emphasizes either realism or interaction separately, I will combine intuitive hand-based interactions with visually engaging gameplay elements like shooting asteroids. This approach directly involves human-computer interaction because players will use natural gestures to interact with objects and control game mechanics, such as grabbing weapons and shooting targets, thereby providing a more immersive and responsive user experience.
  The VR game prototype will feature a detailed moon base where players can move around freely. Players will see their virtual hands, pick up a laser gun, and use it to shoot incoming asteroids. Visually, the interface will be minimalistic, showing essential elements like score and timer in floating displays within the player's field of view. The technology involves Unity for game development, Meta Quest 3 for VR interaction, and Unity’s XR interaction toolkit for hand movements and object interactions.
To test the effectiveness of the interaction methods, I will conduct a simple experiment measuring how quickly and accurately participants can shoot asteroids using hand-based controls. The independent variables will include the interaction technique (using hand gestures versus a standard controller). The dependent variables will be accuracy (number of asteroids successfully hit) and response time (how quickly users react and shoot after asteroids appear).

  For this project, I will utilize Unity Engine, Unity Hub, Meta Quest 3 headset, and Unity’s XR interaction toolkit. The Meta Quest 3 headset will allow for wireless VR experiences, making the game comfortable and immersive. Unity’s XR interaction toolkit will facilitate natural hand movements and interactions in the VR environment. Additionally, C# programming will be used extensively for managing interactions, game logic, and object behaviors within the VR space.
  
